{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/caleb-stewart/Trademark-Analysis-Identification-Tool/blob/main/video_trait.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "id": "yZH2zAlT4VCs",
    "jupyter": {
     "outputs_hidden": true
    },
    "outputId": "3a7bfd70-1add-4faf-f1d8-2cadb05f528e",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
      "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (2.0.2)\n",
      "Collecting ultralytics\n",
      "  Downloading ultralytics-8.3.99-py3-none-any.whl.metadata (37 kB)\n",
      "Requirement already satisfied: numpy<=2.1.1,>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.11.0.86)\n",
      "Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.1.0)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n",
      "Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n",
      "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.14.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n",
      "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: pandas>=1.1.4 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.2.2)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.13.2)\n",
      "Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n",
      "  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.1.4->ultralytics) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.1.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.13.0)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Downloading ultralytics-8.3.99-py3-none-any.whl (976 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m976.9/976.9 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-curand-cu12\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
      "  Attempting uninstall: nvidia-cufft-cu12\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
      "  Attempting uninstall: nvidia-cublas-cu12\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
      "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.99 ultralytics-thop-2.0.14\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
      "Collecting faiss-cpu\n",
      "  Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
      "Downloading faiss_cpu-1.10.0-cp311-cp311-manylinux_2_28_x86_64.whl (30.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m57.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\n",
      "Successfully installed faiss-cpu-1.10.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install opencv-python\n",
    "# !pip install ultralytics\n",
    "# !pip install pillow\n",
    "# !pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "of1caxJ-4ZOo",
    "outputId": "232e2b72-139c-491b-df82-1336da5a1153"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as tr\n",
    "import cv2\n",
    "import faiss\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel, BeitFeatureExtractor, BeitModel\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n",
    "from ultralytics import YOLO\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QwLb4I1n4suc"
   },
   "outputs": [],
   "source": [
    "class EmbeddingExtractor:\n",
    "    \"\"\"Class for extracting image embeddings using ResNet-50, CLIP, and BEiT.\"\"\"\n",
    "\n",
    "    def __init__(self, device=None):\n",
    "        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "        # Load ResNet-50 model\n",
    "        self.resnet = torchvision.models.resnet50(pretrained=True)\n",
    "        self.resnet.fc = nn.Identity()\n",
    "        self.resnet = self.resnet.to(self.device).eval()\n",
    "\n",
    "        # Load CLIP model\n",
    "        self.clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\").to(self.device).eval()\n",
    "        self.clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "        # Load BEiT model\n",
    "        self.beit_model = BeitModel.from_pretrained(\"microsoft/beit-base-patch16-224\").to(self.device).eval()\n",
    "        self.beit_processor = BeitFeatureExtractor.from_pretrained(\"microsoft/beit-base-patch16-224\")\n",
    "\n",
    "    def preprocess_resnet(self, img):\n",
    "        transformations = tr.Compose([\n",
    "            tr.Resize((224, 224)),\n",
    "            tr.ToTensor(),\n",
    "            tr.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
    "        ])\n",
    "        img = transformations(img).unsqueeze(0).to(self.device)\n",
    "        return img\n",
    "\n",
    "    def preprocess_clip(self, img):\n",
    "        return self.clip_processor(images=img, return_tensors=\"pt\")[\"pixel_values\"].to(self.device)\n",
    "\n",
    "    def preprocess_beit(self, img):\n",
    "        return self.beit_processor(images=img, return_tensors=\"pt\")[\"pixel_values\"].to(self.device)\n",
    "\n",
    "    def get_embedding(self, img, model_name=\"resnet\"):\n",
    "\n",
    "        img = Image.fromarray(img)\n",
    "\n",
    "        if model_name == \"resnet\":\n",
    "            img_tensor = self.preprocess_resnet(img)\n",
    "            with torch.no_grad():\n",
    "                embedding = self.resnet(img_tensor).cpu().numpy()\n",
    "\n",
    "        elif model_name == \"clip\":\n",
    "            img_tensor = self.preprocess_clip(img)\n",
    "            with torch.no_grad():\n",
    "                embedding = self.clip_model.get_image_features(img_tensor).cpu().numpy()\n",
    "\n",
    "        elif model_name == \"beit\":\n",
    "            img_tensor = self.preprocess_beit(img)\n",
    "            with torch.no_grad():\n",
    "                embedding = self.beit_model(img_tensor).last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model name. Choose from: resnet, clip, beit.\")\n",
    "\n",
    "        return embedding\n",
    "\n",
    "    @staticmethod\n",
    "    def cosine_similarity(emb1, emb2):\n",
    "\n",
    "        return torch.nn.functional.cosine_similarity(torch.tensor(emb1), torch.tensor(emb2)).item()\n",
    "\n",
    "    @staticmethod\n",
    "    def euclidean_distance(emb1, emb2):\n",
    "\n",
    "        return np.linalg.norm(emb1 - emb2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 716,
     "referenced_widgets": [
      "f1d12d1f5e7f4129ba55bfc72750e970",
      "da313ccb05814ab0ae6765db736cd16a",
      "30096ffabac24d048738981bdc19efbf",
      "423391843f19413a8c55857052df9647",
      "f30835cf463e40ff8185d2eab404ed1f",
      "b9377607876e413da8d1dae56a9c019b",
      "5267ee60df3c4899bb4446c9684a789b",
      "46e3d38d5a304e938cfd19700e619e13",
      "fca583db47754069bbee6323ee9f5391",
      "215be1c676dd42998a6ffbf69fe1c9d4",
      "7444d9f63cb74a83867d8e4f2cf3b078",
      "8646c9bfa811413f946a2bc50a1c67af",
      "948378b3fb784b88b15d88ac727999fa",
      "8fd6f5ecbc164f5990c30d2102c89e51",
      "41355badb84143138a9e25d31159ce43",
      "f4cd7965f3d64ad08cee796b394a2476",
      "5fd18561fca841eabaaff88287f73aaa",
      "d9cccb9d6f8e49fa95addf0a9e5238ef",
      "57828f91158a4683b156d48a40986dc6",
      "1f14f84fd26a46caabb467f61d10da63",
      "d24305fd08f4417881203bb8950b8ecb",
      "958dfb8fc18547d39e5a0d6553312767",
      "4adc2ac7fb8741289cf3a08f0208cbc0",
      "ad7b04f04f4a4cdd8a2b58f9ebd076b7",
      "8693b9e4971742079720c4d035b2480b",
      "8f4060e053294bf182a010b9d1c3bb96",
      "63f6371bd1564d2d9c85c07d472b4dbf",
      "510d8ff6088f4033ac28719205b3f750",
      "3e1f2d0cf8ba4baf8d22be0bbafd2742",
      "4b9c0594290c466485a8bb55c721030d",
      "845dad720be14929b391fd5c72069f73",
      "2454641381d144c2aca2dcfdf2a99c05",
      "cfbe12e3ffb0456eb748c537699cca4a",
      "b9e6a8e64dff439b969955eb52a1c104",
      "98e3fcc7d5a7481fbb9362b2c1247341",
      "2206eb6700404d688d2bc5713239a5e1",
      "093615d7c6874980b0715a55ad37166b",
      "74a7fdbdd4af4716a0a7bd4a5bfb2a00",
      "3c5e9bd832a14559996eb1f276fafe77",
      "62f9b10a279c48ac8e0fe05dd5a8a3f1",
      "a4b8d433bb404a9fa8c024d17d518d13",
      "c5b5370b75a240f2a87f5a732c7a43fa",
      "e4c618e720af425c84bcce18265b1a2d",
      "270397b6f4e7416ba98224421a592ae0",
      "1ad5e854641c454a820c56d30892c105",
      "efaa27f863184e18af5a0f31cc90329f",
      "6468af196d7d48918e6dcdc65dc91c92",
      "3097fb8a15e64cf68912190dd31d1096",
      "44c2163472d14ea9abbde6961a20dd38",
      "700006591d404f3398d767d41130acf4",
      "e21f24abd58a43fc9359d19a3a819154",
      "258bdbe65a604233ae5d5bbbdd0d2961",
      "cce62f92d53c4cbc8ddbb7b8490e5642",
      "89f7f053443b476c97c2bca76010a003",
      "4f18e3cc63e5439fa4a68141abf2cb05",
      "fc4aef0638ae448697ad745c07e04fe6",
      "6e6aa27b5fe243cd97955a5929487ce4",
      "03c272b80fdf46ea9a85424e44d5e8d0",
      "fb17989c433e4b8b935454ac10fbcdd8",
      "9a13baa7aa4a49e4ae7f82e0e84d75f7",
      "ea91d7399fa448bba139fadd28132074",
      "29d3a89e685247a8ba306a895558420e",
      "411bf6bef47241f59d96bfedc5801663",
      "57fd0dbb654c45e8b2f908588c1f71d5",
      "c8eeaa39dbf04a5b82e8f7709d145377",
      "188a2637964c4f06b6d9d7aa570df3f7",
      "159187c818b54972941ab58a09c9bbb3",
      "be58cc0cfe0c417f83f86fd254542c7a",
      "363ed3e58f304861a9e3fcdfd652c73e",
      "36adee2c781e476b8c35ec9ec53c66f4",
      "107575eef36045d9a2054301e4dbcad8",
      "edff5823668843fc93b3194d7d200537",
      "d4fc1c33cbd14107ae62aa7594288211",
      "e4fa653c579a48b6a75a06b1d262694e",
      "67bef8f6e3c0417e8a84d0eeb19a128c",
      "efc544d15b4f4d73b2e77684b283feab",
      "98c1d149972b4b33b2878daae8036eaf",
      "0f5aeaecb12440a1a5e0cdb359d77e30",
      "2d81f48b0c484d7785a7ef915f1d5a0b",
      "f70e63604ba944fbb0ed0ffaf8506f9a",
      "fdbf41b5cbec48a4916b77d5ebb70ac2",
      "bdb958129cc74a73b326c9c5d0de9283",
      "1ca277659fe949d093a96e95dacde41e",
      "23e662abd1dd460cb0fad3acd58da2a5",
      "2337bfaa230f42869ec3488ee4e9375d",
      "916be42a53124b62b1a62426c3e26527",
      "5cd68ac1551440758f9aa879a60ea3db",
      "4591fbc1c0474988ad5cf9f58302b3bb",
      "3e1cd294107c4a62bd0bf3d02f3242f5",
      "56447ac94d7c4a67bdc1e8419cfd4911",
      "aa2870ea7c8e41eca4ee02d90592a109",
      "e135dd10cd6a41dda81831cfe998d5bc",
      "03f888d62d6541789da05722e5834dd5",
      "fddb427005eb45a3a238dab7fdc7e70e",
      "e80c99c4467545738f204938112d3aa9",
      "83eac6c4021d47e4ae5bc0c66d280d9f",
      "e8057d60629c4c25ace6c27c6b7d1457",
      "b5646402495d418a8782dd8247bccdfd",
      "75ba66eab29243c0823c48088df288c4",
      "99d9a455a4744d35ad798dd1eb4ea95b",
      "f69e1c4fd7954d4caf04acd464bd4758",
      "8b2d72b478a64964854fb3773515b42c",
      "4565c74c30364ee5b9e2b1b6314a2017",
      "89d485d4ddfe4ad3bbee52937b495ccb",
      "ff48f8c198fc4563a98804f4b6b3a55b",
      "e97917111f5b4f4ab223a597666de83d",
      "65e392c6684f44179f485c7d717c06b8",
      "4675a2c80a31444fa4e54a3c55979268",
      "37d3414e58ec4ef7907a4ff5d31f9d3c",
      "9249a8908dba44b8a399b667ecd59f03",
      "12be1112e1494b088c714c35aca50486",
      "d972f458ec4b48dfae5dc7663aed76c0",
      "4c22269fefb24294821461eecc66b619",
      "d07d45babfa141338ce0d0f65707a331",
      "3991384dfaa84c578e7f3c1bffab85de",
      "c2333ff3a641453795ade83ca18d1391",
      "37981d55d5d84b25a6c0c07bf259ccd3",
      "f8854b8390124e7fa628cd6c65bbc1b1",
      "83a36c03249b4a5c811c24a89d8378d4",
      "2f9c26f5a3374b99834e81c4f1ff7688",
      "667abc5b5d6441668b0f2dffafdd6638",
      "9a6de4ac749f414abee9f342731aef8f",
      "94da05c849494bb9ba4b819ff3c574dd",
      "f50e450471a9452088dd28e962ae847f",
      "1c6235a672c3443e848ed440a3182155",
      "1c73996b02604302b3e0f67c41e7b11f",
      "4f96af94c3f54f7e93f1f4396943eef7",
      "3570f8e3d279499dae74c64aa94a728c",
      "19b39c7b58114c71a2669b6ec10ae008",
      "1b94f8aa6ae7406ba91df3f35f7da41f",
      "42840d6628474e9d8c44f1fdef7b3d46",
      "b71cb728be3c46e3b3b5e5f2ff2d57b4"
     ]
    },
    "id": "Wep6bZdg4wCS",
    "outputId": "2a2a88d6-286c-48a7-93bb-bf3adf359b49"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "C:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\caleb\\.cache\\huggingface\\hub\\models--openai--clip-vit-base-patch32. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "C:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\transformers\\models\\beit\\feature_extraction_beit.py:28: FutureWarning: The class BeitFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use BeitImageProcessor instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\caleb\\anaconda3\\Lib\\site-packages\\transformers\\utils\\deprecation.py:172: UserWarning: The following named arguments are not valid for `BeitFeatureExtractor.__init__` and were ignored: 'feature_extractor_type'\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"best.pt\")\n",
    "similarity_checker = EmbeddingExtractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kCYxHTDb41nM"
   },
   "outputs": [],
   "source": [
    "def extract_logo_regions(image, save_crop=False, output_dir=\"cropped_logos\"):\n",
    "    \"\"\"Runs YOLO on an image and extracts detected logo regions.\"\"\"\n",
    "\n",
    "    # Check if input is a file path or an image array\n",
    "    if isinstance(image, str):\n",
    "        img = cv2.imread(image)\n",
    "    else:\n",
    "        img = image\n",
    "\n",
    "    if img is None:\n",
    "        print(\"Error: Could not load image.\")\n",
    "        return [], []\n",
    "\n",
    "    results = model(img)\n",
    "    logo_regions = []\n",
    "    bounding_boxes = []\n",
    "\n",
    "    if save_crop and not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    for idx, box in enumerate(results[0].boxes):\n",
    "        xyxy = box.xyxy[0].tolist()\n",
    "        x1, y1, x2, y2 = map(int, xyxy)\n",
    "        cropped_logo = img[y1:y2, x1:x2]  # extract detected region\n",
    "\n",
    "        if save_crop and cropped_logo.size > 0:\n",
    "            cropped_logo_path = os.path.join(output_dir, f\"cropped_logo_{idx}.jpg\")\n",
    "            cv2.imwrite(cropped_logo_path, cropped_logo)\n",
    "            print(f\"Logo {idx} saved: {cropped_logo_path}\")\n",
    "\n",
    "        if cropped_logo.size > 0:\n",
    "            logo_regions.append(cropped_logo)\n",
    "            bounding_boxes.append((x1, y1, x2, y2))\n",
    "            print(f\"Logo {idx} detected at coordinates: ({x1}, {y1}) -> ({x2}, {y2})\")\n",
    "\n",
    "    return logo_regions, bounding_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "id": "hOq5D4Z84PXC"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torchvision.transforms as tr\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel, BeitModel, BeitFeatureExtractor\n",
    "\n",
    "thresholds = {\n",
    "  'beit': {'cosine': .3, 'euclidean': 110},\n",
    "  'clip': {'cosine': .65, 'euclidean': 7.5},\n",
    "  'resnet': {'cosine': .75, 'euclidean': 50}\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def process_video(input_video_path, output_video_path, reference_image_path, similarity_threshold=0.50, frame_skip=5):\n",
    "    cap = cv2.VideoCapture(input_video_path)\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
    "\n",
    "    frame_idx = 0\n",
    "    reference_logos, _ = extract_logo_regions(reference_image_path, save_crop=False)\n",
    "\n",
    "    reference_embeddings = {model: [] for model in [\"resnet\", \"beit\", \"clip\"]}\n",
    "    for ref_logo in reference_logos:\n",
    "      for model_name in reference_embeddings.keys():\n",
    "          reference_embeddings[model_name].append(similarity_checker.get_embedding(ref_logo, model_name))\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break  # stop if video ends\n",
    "\n",
    "        if frame_idx % frame_skip == 0:  # process every 5th frame\n",
    "            print(f\"Processing frame {frame_idx}\")\n",
    "\n",
    "            # extract detected logos from the current frame\n",
    "            input_logos, input_bboxes = extract_logo_regions(frame, save_crop=False)\n",
    "\n",
    "            if not input_logos or not reference_logos:\n",
    "                print(\"No logos detected in one or both images.\")\n",
    "            else:\n",
    "                save_frame = False\n",
    "                for idx, input_logo in enumerate(input_logos):\n",
    "                    votes = 0\n",
    "                    input_embeddings = {model: similarity_checker.get_embedding(input_logo, model) for model in [\"resnet\", \"beit\", \"clip\"]}\n",
    "                    \n",
    "                    for model_name in [\"resnet\", \"beit\", \"clip\"]:\n",
    "                      for ref_embedding in reference_embeddings[model_name]:\n",
    "                        cosine_sim = similarity_checker.cosine_similarity(input_embeddings[model_name], ref_embedding)\n",
    "                        euclidean_dist = similarity_checker.euclidean_distance(input_embeddings[model_name], ref_embedding)\n",
    "\n",
    "                        if cosine_sim >= thresholds[model_name]['cosine']:\n",
    "                            votes += 1\n",
    "                        if euclidean_dist <= thresholds[model_name]['euclidean']:\n",
    "                            votes += 1\n",
    "\n",
    "                    if votes >= 2:\n",
    "                      x1, y1, x2, y2 = input_bboxes[idx]\n",
    "                      cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 255, 255), 5)\n",
    "                      save_frame = True\n",
    "                      break\n",
    "\n",
    "                if save_frame:\n",
    "                    print(f\"Match found in frame {frame_idx}!\")\n",
    "\n",
    "        out.write(frame)  # write processed frame to output\n",
    "\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n",
    "    print(f\"Processed video saved as {output_video_path}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qMPCh-zu4fCe",
    "outputId": "3f5e6a9d-75d8-46d3-8e76-d908920467bb",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x640 1 logo, 131.2ms\n",
      "Speed: 7.6ms preprocess, 131.2ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 640)\n",
      "Logo 0 detected at coordinates: (2, 6) -> (221, 224)\n",
      "Processing frame 0\n",
      "\n",
      "0: 384x640 1 logo, 120.6ms\n",
      "Speed: 3.8ms preprocess, 120.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1128, 503) -> (1345, 654)\n",
      "Match found in frame 0!\n",
      "Processing frame 5\n",
      "\n",
      "0: 384x640 1 logo, 82.5ms\n",
      "Speed: 2.9ms preprocess, 82.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1129, 504) -> (1343, 654)\n",
      "Match found in frame 5!\n",
      "Processing frame 10\n",
      "\n",
      "0: 384x640 1 logo, 98.8ms\n",
      "Speed: 3.5ms preprocess, 98.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1129, 503) -> (1342, 653)\n",
      "Match found in frame 10!\n",
      "Processing frame 15\n",
      "\n",
      "0: 384x640 1 logo, 87.5ms\n",
      "Speed: 3.3ms preprocess, 87.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1128, 503) -> (1341, 653)\n",
      "Match found in frame 15!\n",
      "Processing frame 20\n",
      "\n",
      "0: 384x640 1 logo, 99.0ms\n",
      "Speed: 3.2ms preprocess, 99.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1128, 502) -> (1341, 653)\n",
      "Match found in frame 20!\n",
      "Processing frame 25\n",
      "\n",
      "0: 384x640 1 logo, 102.0ms\n",
      "Speed: 3.7ms preprocess, 102.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1127, 503) -> (1339, 652)\n",
      "Match found in frame 25!\n",
      "Processing frame 30\n",
      "\n",
      "0: 384x640 1 logo, 140.6ms\n",
      "Speed: 3.5ms preprocess, 140.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1127, 502) -> (1338, 652)\n",
      "Match found in frame 30!\n",
      "Processing frame 35\n",
      "\n",
      "0: 384x640 1 logo, 94.7ms\n",
      "Speed: 3.5ms preprocess, 94.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1126, 500) -> (1338, 652)\n",
      "Match found in frame 35!\n",
      "Processing frame 40\n",
      "\n",
      "0: 384x640 1 logo, 109.3ms\n",
      "Speed: 3.4ms preprocess, 109.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1125, 500) -> (1337, 652)\n",
      "Match found in frame 40!\n",
      "Processing frame 45\n",
      "\n",
      "0: 384x640 1 logo, 108.6ms\n",
      "Speed: 3.7ms preprocess, 108.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1119, 497) -> (1337, 653)\n",
      "Match found in frame 45!\n",
      "Processing frame 50\n",
      "\n",
      "0: 384x640 1 logo, 104.7ms\n",
      "Speed: 3.6ms preprocess, 104.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1123, 496) -> (1337, 652)\n",
      "Match found in frame 50!\n",
      "Processing frame 55\n",
      "\n",
      "0: 384x640 1 logo, 114.6ms\n",
      "Speed: 3.9ms preprocess, 114.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1117, 491) -> (1338, 653)\n",
      "Match found in frame 55!\n",
      "Processing frame 60\n",
      "\n",
      "0: 384x640 1 logo, 242.4ms\n",
      "Speed: 6.8ms preprocess, 242.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1116, 491) -> (1337, 654)\n",
      "Match found in frame 60!\n",
      "Processing frame 65\n",
      "\n",
      "0: 384x640 1 logo, 97.7ms\n",
      "Speed: 3.2ms preprocess, 97.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1118, 488) -> (1336, 653)\n",
      "Match found in frame 65!\n",
      "Processing frame 70\n",
      "\n",
      "0: 384x640 1 logo, 239.2ms\n",
      "Speed: 4.0ms preprocess, 239.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1118, 488) -> (1336, 652)\n",
      "Match found in frame 70!\n",
      "Processing frame 75\n",
      "\n",
      "0: 384x640 1 logo, 107.6ms\n",
      "Speed: 3.7ms preprocess, 107.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1117, 487) -> (1333, 652)\n",
      "Match found in frame 75!\n",
      "Processing frame 80\n",
      "\n",
      "0: 384x640 1 logo, 111.3ms\n",
      "Speed: 3.2ms preprocess, 111.3ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1117, 487) -> (1334, 653)\n",
      "Match found in frame 80!\n",
      "Processing frame 85\n",
      "\n",
      "0: 384x640 1 logo, 152.5ms\n",
      "Speed: 4.7ms preprocess, 152.5ms inference, 4.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1115, 485) -> (1332, 654)\n",
      "Match found in frame 85!\n",
      "Processing frame 90\n",
      "\n",
      "0: 384x640 1 logo, 108.3ms\n",
      "Speed: 3.2ms preprocess, 108.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1115, 486) -> (1331, 654)\n",
      "Match found in frame 90!\n",
      "Processing frame 95\n",
      "\n",
      "0: 384x640 1 logo, 106.2ms\n",
      "Speed: 3.2ms preprocess, 106.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1113, 490) -> (1329, 654)\n",
      "Match found in frame 95!\n",
      "Processing frame 100\n",
      "\n",
      "0: 384x640 1 logo, 106.1ms\n",
      "Speed: 3.3ms preprocess, 106.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1112, 488) -> (1329, 654)\n",
      "Match found in frame 100!\n",
      "Processing frame 105\n",
      "\n",
      "0: 384x640 1 logo, 109.2ms\n",
      "Speed: 3.8ms preprocess, 109.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1106, 486) -> (1330, 654)\n",
      "Match found in frame 105!\n",
      "Processing frame 110\n",
      "\n",
      "0: 384x640 1 logo, 106.4ms\n",
      "Speed: 3.8ms preprocess, 106.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1105, 486) -> (1329, 654)\n",
      "Match found in frame 110!\n",
      "Processing frame 115\n",
      "\n",
      "0: 384x640 1 logo, 110.3ms\n",
      "Speed: 3.6ms preprocess, 110.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (1100, 480) -> (1328, 663)\n",
      "Match found in frame 115!\n",
      "Processing frame 120\n",
      "\n",
      "0: 384x640 (no detections), 111.4ms\n",
      "Speed: 3.7ms preprocess, 111.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 125\n",
      "\n",
      "0: 384x640 (no detections), 100.8ms\n",
      "Speed: 3.5ms preprocess, 100.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 130\n",
      "\n",
      "0: 384x640 (no detections), 86.8ms\n",
      "Speed: 3.1ms preprocess, 86.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 135\n",
      "\n",
      "0: 384x640 (no detections), 89.4ms\n",
      "Speed: 3.3ms preprocess, 89.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 140\n",
      "\n",
      "0: 384x640 (no detections), 88.4ms\n",
      "Speed: 3.2ms preprocess, 88.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 145\n",
      "\n",
      "0: 384x640 (no detections), 94.8ms\n",
      "Speed: 3.4ms preprocess, 94.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 150\n",
      "\n",
      "0: 384x640 (no detections), 95.0ms\n",
      "Speed: 2.9ms preprocess, 95.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 155\n",
      "\n",
      "0: 384x640 (no detections), 87.5ms\n",
      "Speed: 3.0ms preprocess, 87.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 160\n",
      "\n",
      "0: 384x640 (no detections), 90.2ms\n",
      "Speed: 3.2ms preprocess, 90.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 165\n",
      "\n",
      "0: 384x640 (no detections), 93.3ms\n",
      "Speed: 2.9ms preprocess, 93.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 170\n",
      "\n",
      "0: 384x640 (no detections), 85.5ms\n",
      "Speed: 3.0ms preprocess, 85.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 175\n",
      "\n",
      "0: 384x640 (no detections), 82.4ms\n",
      "Speed: 2.7ms preprocess, 82.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 180\n",
      "\n",
      "0: 384x640 (no detections), 80.4ms\n",
      "Speed: 2.7ms preprocess, 80.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 185\n",
      "\n",
      "0: 384x640 (no detections), 81.8ms\n",
      "Speed: 3.0ms preprocess, 81.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 190\n",
      "\n",
      "0: 384x640 (no detections), 86.8ms\n",
      "Speed: 3.2ms preprocess, 86.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 195\n",
      "\n",
      "0: 384x640 (no detections), 83.3ms\n",
      "Speed: 3.1ms preprocess, 83.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 200\n",
      "\n",
      "0: 384x640 (no detections), 79.6ms\n",
      "Speed: 3.6ms preprocess, 79.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 205\n",
      "\n",
      "0: 384x640 (no detections), 92.0ms\n",
      "Speed: 3.1ms preprocess, 92.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 210\n",
      "\n",
      "0: 384x640 (no detections), 84.3ms\n",
      "Speed: 2.9ms preprocess, 84.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 215\n",
      "\n",
      "0: 384x640 (no detections), 75.1ms\n",
      "Speed: 2.8ms preprocess, 75.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 220\n",
      "\n",
      "0: 384x640 (no detections), 85.2ms\n",
      "Speed: 2.9ms preprocess, 85.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 225\n",
      "\n",
      "0: 384x640 (no detections), 82.6ms\n",
      "Speed: 3.0ms preprocess, 82.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 230\n",
      "\n",
      "0: 384x640 (no detections), 82.3ms\n",
      "Speed: 2.8ms preprocess, 82.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 235\n",
      "\n",
      "0: 384x640 (no detections), 82.2ms\n",
      "Speed: 3.0ms preprocess, 82.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 240\n",
      "\n",
      "0: 384x640 (no detections), 79.0ms\n",
      "Speed: 2.9ms preprocess, 79.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 245\n",
      "\n",
      "0: 384x640 (no detections), 82.0ms\n",
      "Speed: 2.8ms preprocess, 82.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 250\n",
      "\n",
      "0: 384x640 (no detections), 80.3ms\n",
      "Speed: 2.8ms preprocess, 80.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 255\n",
      "\n",
      "0: 384x640 (no detections), 87.3ms\n",
      "Speed: 3.0ms preprocess, 87.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 260\n",
      "\n",
      "0: 384x640 (no detections), 84.6ms\n",
      "Speed: 2.9ms preprocess, 84.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 265\n",
      "\n",
      "0: 384x640 (no detections), 93.4ms\n",
      "Speed: 2.9ms preprocess, 93.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 270\n",
      "\n",
      "0: 384x640 (no detections), 84.1ms\n",
      "Speed: 2.8ms preprocess, 84.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 275\n",
      "\n",
      "0: 384x640 (no detections), 84.3ms\n",
      "Speed: 2.8ms preprocess, 84.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 280\n",
      "\n",
      "0: 384x640 (no detections), 90.0ms\n",
      "Speed: 2.9ms preprocess, 90.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 285\n",
      "\n",
      "0: 384x640 (no detections), 80.3ms\n",
      "Speed: 2.8ms preprocess, 80.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 290\n",
      "\n",
      "0: 384x640 (no detections), 77.3ms\n",
      "Speed: 3.1ms preprocess, 77.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 295\n",
      "\n",
      "0: 384x640 (no detections), 78.1ms\n",
      "Speed: 3.1ms preprocess, 78.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 300\n",
      "\n",
      "0: 384x640 (no detections), 79.4ms\n",
      "Speed: 3.0ms preprocess, 79.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 305\n",
      "\n",
      "0: 384x640 (no detections), 81.5ms\n",
      "Speed: 2.6ms preprocess, 81.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 310\n",
      "\n",
      "0: 384x640 (no detections), 88.5ms\n",
      "Speed: 2.8ms preprocess, 88.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 315\n",
      "\n",
      "0: 384x640 (no detections), 85.1ms\n",
      "Speed: 2.9ms preprocess, 85.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 320\n",
      "\n",
      "0: 384x640 (no detections), 82.8ms\n",
      "Speed: 2.9ms preprocess, 82.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 325\n",
      "\n",
      "0: 384x640 (no detections), 89.3ms\n",
      "Speed: 2.8ms preprocess, 89.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 330\n",
      "\n",
      "0: 384x640 (no detections), 80.9ms\n",
      "Speed: 2.9ms preprocess, 80.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 335\n",
      "\n",
      "0: 384x640 (no detections), 87.6ms\n",
      "Speed: 3.0ms preprocess, 87.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 340\n",
      "\n",
      "0: 384x640 (no detections), 83.8ms\n",
      "Speed: 3.1ms preprocess, 83.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 345\n",
      "\n",
      "0: 384x640 (no detections), 83.9ms\n",
      "Speed: 3.0ms preprocess, 83.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 350\n",
      "\n",
      "0: 384x640 (no detections), 79.8ms\n",
      "Speed: 2.7ms preprocess, 79.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 355\n",
      "\n",
      "0: 384x640 (no detections), 78.7ms\n",
      "Speed: 2.8ms preprocess, 78.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 360\n",
      "\n",
      "0: 384x640 (no detections), 80.3ms\n",
      "Speed: 3.5ms preprocess, 80.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 365\n",
      "\n",
      "0: 384x640 (no detections), 93.0ms\n",
      "Speed: 3.0ms preprocess, 93.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 370\n",
      "\n",
      "0: 384x640 (no detections), 87.4ms\n",
      "Speed: 3.3ms preprocess, 87.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 375\n",
      "\n",
      "0: 384x640 1 logo, 93.0ms\n",
      "Speed: 2.9ms preprocess, 93.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (810, 432) -> (952, 552)\n",
      "Processing frame 380\n",
      "\n",
      "0: 384x640 (no detections), 102.6ms\n",
      "Speed: 3.2ms preprocess, 102.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 385\n",
      "\n",
      "0: 384x640 (no detections), 90.7ms\n",
      "Speed: 3.1ms preprocess, 90.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 390\n",
      "\n",
      "0: 384x640 1 logo, 97.4ms\n",
      "Speed: 3.1ms preprocess, 97.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (815, 440) -> (951, 552)\n",
      "Processing frame 395\n",
      "\n",
      "0: 384x640 (no detections), 106.6ms\n",
      "Speed: 4.0ms preprocess, 106.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 400\n",
      "\n",
      "0: 384x640 (no detections), 90.9ms\n",
      "Speed: 3.7ms preprocess, 90.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 405\n",
      "\n",
      "0: 384x640 (no detections), 97.8ms\n",
      "Speed: 3.0ms preprocess, 97.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 410\n",
      "\n",
      "0: 384x640 (no detections), 89.8ms\n",
      "Speed: 2.9ms preprocess, 89.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 415\n",
      "\n",
      "0: 384x640 (no detections), 100.1ms\n",
      "Speed: 3.3ms preprocess, 100.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 420\n",
      "\n",
      "0: 384x640 (no detections), 104.7ms\n",
      "Speed: 3.1ms preprocess, 104.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 425\n",
      "\n",
      "0: 384x640 (no detections), 89.3ms\n",
      "Speed: 2.5ms preprocess, 89.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 430\n",
      "\n",
      "0: 384x640 (no detections), 95.2ms\n",
      "Speed: 2.8ms preprocess, 95.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 435\n",
      "\n",
      "0: 384x640 (no detections), 96.4ms\n",
      "Speed: 2.7ms preprocess, 96.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 440\n",
      "\n",
      "0: 384x640 (no detections), 96.0ms\n",
      "Speed: 2.7ms preprocess, 96.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 445\n",
      "\n",
      "0: 384x640 (no detections), 113.6ms\n",
      "Speed: 3.4ms preprocess, 113.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 450\n",
      "\n",
      "0: 384x640 (no detections), 92.4ms\n",
      "Speed: 3.2ms preprocess, 92.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 455\n",
      "\n",
      "0: 384x640 (no detections), 91.7ms\n",
      "Speed: 3.0ms preprocess, 91.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 460\n",
      "\n",
      "0: 384x640 1 logo, 81.8ms\n",
      "Speed: 2.8ms preprocess, 81.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (721, 452) -> (1301, 709)\n",
      "Processing frame 465\n",
      "\n",
      "0: 384x640 (no detections), 105.4ms\n",
      "Speed: 3.6ms preprocess, 105.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 470\n",
      "\n",
      "0: 384x640 (no detections), 84.5ms\n",
      "Speed: 3.0ms preprocess, 84.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 475\n",
      "\n",
      "0: 384x640 (no detections), 83.5ms\n",
      "Speed: 2.8ms preprocess, 83.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 480\n",
      "\n",
      "0: 384x640 (no detections), 84.0ms\n",
      "Speed: 3.7ms preprocess, 84.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 485\n",
      "\n",
      "0: 384x640 (no detections), 83.1ms\n",
      "Speed: 2.8ms preprocess, 83.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 490\n",
      "\n",
      "0: 384x640 (no detections), 81.9ms\n",
      "Speed: 2.8ms preprocess, 81.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 495\n",
      "\n",
      "0: 384x640 (no detections), 77.5ms\n",
      "Speed: 3.1ms preprocess, 77.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 500\n",
      "\n",
      "0: 384x640 (no detections), 70.1ms\n",
      "Speed: 2.8ms preprocess, 70.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 505\n",
      "\n",
      "0: 384x640 (no detections), 95.0ms\n",
      "Speed: 3.8ms preprocess, 95.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 510\n",
      "\n",
      "0: 384x640 (no detections), 85.1ms\n",
      "Speed: 3.2ms preprocess, 85.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 515\n",
      "\n",
      "0: 384x640 (no detections), 83.9ms\n",
      "Speed: 3.0ms preprocess, 83.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 520\n",
      "\n",
      "0: 384x640 (no detections), 81.7ms\n",
      "Speed: 2.8ms preprocess, 81.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 525\n",
      "\n",
      "0: 384x640 (no detections), 76.9ms\n",
      "Speed: 3.0ms preprocess, 76.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 530\n",
      "\n",
      "0: 384x640 (no detections), 77.5ms\n",
      "Speed: 3.1ms preprocess, 77.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 535\n",
      "\n",
      "0: 384x640 (no detections), 80.1ms\n",
      "Speed: 2.8ms preprocess, 80.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 540\n",
      "\n",
      "0: 384x640 (no detections), 80.2ms\n",
      "Speed: 3.0ms preprocess, 80.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 545\n",
      "\n",
      "0: 384x640 (no detections), 80.0ms\n",
      "Speed: 2.6ms preprocess, 80.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 550\n",
      "\n",
      "0: 384x640 (no detections), 83.5ms\n",
      "Speed: 2.8ms preprocess, 83.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 555\n",
      "\n",
      "0: 384x640 (no detections), 82.7ms\n",
      "Speed: 2.8ms preprocess, 82.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 560\n",
      "\n",
      "0: 384x640 (no detections), 88.7ms\n",
      "Speed: 2.7ms preprocess, 88.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 565\n",
      "\n",
      "0: 384x640 (no detections), 79.0ms\n",
      "Speed: 2.8ms preprocess, 79.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 570\n",
      "\n",
      "0: 384x640 (no detections), 91.2ms\n",
      "Speed: 3.4ms preprocess, 91.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 575\n",
      "\n",
      "0: 384x640 (no detections), 85.7ms\n",
      "Speed: 3.0ms preprocess, 85.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 580\n",
      "\n",
      "0: 384x640 (no detections), 80.2ms\n",
      "Speed: 3.0ms preprocess, 80.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 585\n",
      "\n",
      "0: 384x640 (no detections), 81.4ms\n",
      "Speed: 2.8ms preprocess, 81.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 590\n",
      "\n",
      "0: 384x640 (no detections), 82.2ms\n",
      "Speed: 3.1ms preprocess, 82.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 595\n",
      "\n",
      "0: 384x640 (no detections), 79.4ms\n",
      "Speed: 2.7ms preprocess, 79.4ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 600\n",
      "\n",
      "0: 384x640 (no detections), 78.6ms\n",
      "Speed: 2.6ms preprocess, 78.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 605\n",
      "\n",
      "0: 384x640 (no detections), 82.0ms\n",
      "Speed: 2.7ms preprocess, 82.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 610\n",
      "\n",
      "0: 384x640 (no detections), 89.0ms\n",
      "Speed: 2.9ms preprocess, 89.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 615\n",
      "\n",
      "0: 384x640 (no detections), 79.7ms\n",
      "Speed: 2.9ms preprocess, 79.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 620\n",
      "\n",
      "0: 384x640 1 logo, 93.8ms\n",
      "Speed: 3.5ms preprocess, 93.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (849, 104) -> (1044, 385)\n",
      "Match found in frame 620!\n",
      "Processing frame 625\n",
      "\n",
      "0: 384x640 (no detections), 101.5ms\n",
      "Speed: 3.6ms preprocess, 101.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 630\n",
      "\n",
      "0: 384x640 (no detections), 167.9ms\n",
      "Speed: 6.1ms preprocess, 167.9ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 635\n",
      "\n",
      "0: 384x640 (no detections), 98.2ms\n",
      "Speed: 3.6ms preprocess, 98.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 640\n",
      "\n",
      "0: 384x640 (no detections), 116.6ms\n",
      "Speed: 4.3ms preprocess, 116.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 645\n",
      "\n",
      "0: 384x640 (no detections), 119.9ms\n",
      "Speed: 3.9ms preprocess, 119.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 650\n",
      "\n",
      "0: 384x640 (no detections), 117.4ms\n",
      "Speed: 4.3ms preprocess, 117.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 655\n",
      "\n",
      "0: 384x640 (no detections), 96.7ms\n",
      "Speed: 4.2ms preprocess, 96.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 660\n",
      "\n",
      "0: 384x640 (no detections), 83.8ms\n",
      "Speed: 3.4ms preprocess, 83.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 665\n",
      "\n",
      "0: 384x640 (no detections), 86.0ms\n",
      "Speed: 2.7ms preprocess, 86.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 670\n",
      "\n",
      "0: 384x640 (no detections), 80.7ms\n",
      "Speed: 3.1ms preprocess, 80.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 675\n",
      "\n",
      "0: 384x640 (no detections), 89.3ms\n",
      "Speed: 3.7ms preprocess, 89.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 680\n",
      "\n",
      "0: 384x640 (no detections), 81.1ms\n",
      "Speed: 2.7ms preprocess, 81.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 685\n",
      "\n",
      "0: 384x640 (no detections), 84.8ms\n",
      "Speed: 2.8ms preprocess, 84.8ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 690\n",
      "\n",
      "0: 384x640 (no detections), 81.6ms\n",
      "Speed: 2.9ms preprocess, 81.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 695\n",
      "\n",
      "0: 384x640 (no detections), 89.4ms\n",
      "Speed: 4.3ms preprocess, 89.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 700\n",
      "\n",
      "0: 384x640 (no detections), 91.4ms\n",
      "Speed: 3.1ms preprocess, 91.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 705\n",
      "\n",
      "0: 384x640 (no detections), 94.9ms\n",
      "Speed: 3.1ms preprocess, 94.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 710\n",
      "\n",
      "0: 384x640 (no detections), 89.6ms\n",
      "Speed: 2.9ms preprocess, 89.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 715\n",
      "\n",
      "0: 384x640 (no detections), 91.7ms\n",
      "Speed: 2.8ms preprocess, 91.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 720\n",
      "\n",
      "0: 384x640 (no detections), 86.9ms\n",
      "Speed: 3.0ms preprocess, 86.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 725\n",
      "\n",
      "0: 384x640 (no detections), 85.9ms\n",
      "Speed: 2.6ms preprocess, 85.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 730\n",
      "\n",
      "0: 384x640 (no detections), 83.7ms\n",
      "Speed: 2.6ms preprocess, 83.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 735\n",
      "\n",
      "0: 384x640 (no detections), 99.6ms\n",
      "Speed: 3.5ms preprocess, 99.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 740\n",
      "\n",
      "0: 384x640 (no detections), 78.4ms\n",
      "Speed: 3.0ms preprocess, 78.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 745\n",
      "\n",
      "0: 384x640 (no detections), 81.3ms\n",
      "Speed: 2.7ms preprocess, 81.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 750\n",
      "\n",
      "0: 384x640 (no detections), 74.3ms\n",
      "Speed: 2.6ms preprocess, 74.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 755\n",
      "\n",
      "0: 384x640 (no detections), 83.1ms\n",
      "Speed: 2.3ms preprocess, 83.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 760\n",
      "\n",
      "0: 384x640 (no detections), 92.9ms\n",
      "Speed: 3.0ms preprocess, 92.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 765\n",
      "\n",
      "0: 384x640 (no detections), 91.1ms\n",
      "Speed: 3.1ms preprocess, 91.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 770\n",
      "\n",
      "0: 384x640 (no detections), 91.3ms\n",
      "Speed: 2.6ms preprocess, 91.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 775\n",
      "\n",
      "0: 384x640 (no detections), 78.0ms\n",
      "Speed: 2.9ms preprocess, 78.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 780\n",
      "\n",
      "0: 384x640 (no detections), 76.3ms\n",
      "Speed: 2.7ms preprocess, 76.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 785\n",
      "\n",
      "0: 384x640 (no detections), 81.8ms\n",
      "Speed: 3.0ms preprocess, 81.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 790\n",
      "\n",
      "0: 384x640 (no detections), 79.3ms\n",
      "Speed: 2.9ms preprocess, 79.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 795\n",
      "\n",
      "0: 384x640 (no detections), 79.0ms\n",
      "Speed: 2.8ms preprocess, 79.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 800\n",
      "\n",
      "0: 384x640 (no detections), 82.0ms\n",
      "Speed: 2.9ms preprocess, 82.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 805\n",
      "\n",
      "0: 384x640 (no detections), 85.8ms\n",
      "Speed: 2.6ms preprocess, 85.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 810\n",
      "\n",
      "0: 384x640 (no detections), 78.8ms\n",
      "Speed: 3.0ms preprocess, 78.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 815\n",
      "\n",
      "0: 384x640 (no detections), 83.4ms\n",
      "Speed: 2.9ms preprocess, 83.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 820\n",
      "\n",
      "0: 384x640 (no detections), 77.4ms\n",
      "Speed: 2.8ms preprocess, 77.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 825\n",
      "\n",
      "0: 384x640 (no detections), 80.3ms\n",
      "Speed: 3.0ms preprocess, 80.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 830\n",
      "\n",
      "0: 384x640 (no detections), 78.8ms\n",
      "Speed: 2.7ms preprocess, 78.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 835\n",
      "\n",
      "0: 384x640 (no detections), 84.3ms\n",
      "Speed: 2.9ms preprocess, 84.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 840\n",
      "\n",
      "0: 384x640 (no detections), 72.6ms\n",
      "Speed: 2.7ms preprocess, 72.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 845\n",
      "\n",
      "0: 384x640 (no detections), 84.7ms\n",
      "Speed: 2.9ms preprocess, 84.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 850\n",
      "\n",
      "0: 384x640 (no detections), 76.8ms\n",
      "Speed: 2.9ms preprocess, 76.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 855\n",
      "\n",
      "0: 384x640 (no detections), 76.3ms\n",
      "Speed: 2.7ms preprocess, 76.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 860\n",
      "\n",
      "0: 384x640 (no detections), 75.0ms\n",
      "Speed: 2.8ms preprocess, 75.0ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 865\n",
      "\n",
      "0: 384x640 (no detections), 76.4ms\n",
      "Speed: 2.7ms preprocess, 76.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 870\n",
      "\n",
      "0: 384x640 (no detections), 78.1ms\n",
      "Speed: 2.7ms preprocess, 78.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 875\n",
      "\n",
      "0: 384x640 (no detections), 111.2ms\n",
      "Speed: 4.8ms preprocess, 111.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 880\n",
      "\n",
      "0: 384x640 (no detections), 76.1ms\n",
      "Speed: 2.8ms preprocess, 76.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 885\n",
      "\n",
      "0: 384x640 (no detections), 78.1ms\n",
      "Speed: 3.0ms preprocess, 78.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 890\n",
      "\n",
      "0: 384x640 (no detections), 70.5ms\n",
      "Speed: 3.0ms preprocess, 70.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 895\n",
      "\n",
      "0: 384x640 1 logo, 86.5ms\n",
      "Speed: 3.0ms preprocess, 86.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (579, 164) -> (1916, 902)\n",
      "Match found in frame 895!\n",
      "Processing frame 900\n",
      "\n",
      "0: 384x640 1 logo, 82.1ms\n",
      "Speed: 3.3ms preprocess, 82.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (577, 162) -> (1916, 903)\n",
      "Match found in frame 900!\n",
      "Processing frame 905\n",
      "\n",
      "0: 384x640 1 logo, 92.9ms\n",
      "Speed: 3.3ms preprocess, 92.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (572, 163) -> (1915, 900)\n",
      "Match found in frame 905!\n",
      "Processing frame 910\n",
      "\n",
      "0: 384x640 1 logo, 88.8ms\n",
      "Speed: 3.3ms preprocess, 88.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (566, 161) -> (1916, 899)\n",
      "Match found in frame 910!\n",
      "Processing frame 915\n",
      "\n",
      "0: 384x640 1 logo, 131.9ms\n",
      "Speed: 3.6ms preprocess, 131.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (547, 161) -> (1916, 896)\n",
      "Match found in frame 915!\n",
      "Processing frame 920\n",
      "\n",
      "0: 384x640 1 logo, 100.2ms\n",
      "Speed: 3.8ms preprocess, 100.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (522, 161) -> (1916, 893)\n",
      "Match found in frame 920!\n",
      "Processing frame 925\n",
      "\n",
      "0: 384x640 1 logo, 101.9ms\n",
      "Speed: 3.5ms preprocess, 101.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (498, 160) -> (1917, 892)\n",
      "Match found in frame 925!\n",
      "Processing frame 930\n",
      "\n",
      "0: 384x640 1 logo, 99.2ms\n",
      "Speed: 3.3ms preprocess, 99.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (484, 161) -> (1917, 890)\n",
      "Match found in frame 930!\n",
      "Processing frame 935\n",
      "\n",
      "0: 384x640 1 logo, 93.5ms\n",
      "Speed: 3.9ms preprocess, 93.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (485, 161) -> (1916, 891)\n",
      "Match found in frame 935!\n",
      "Processing frame 940\n",
      "\n",
      "0: 384x640 1 logo, 95.2ms\n",
      "Speed: 3.6ms preprocess, 95.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (488, 161) -> (1916, 890)\n",
      "Match found in frame 940!\n",
      "Processing frame 945\n",
      "\n",
      "0: 384x640 1 logo, 98.9ms\n",
      "Speed: 3.4ms preprocess, 98.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (446, 163) -> (1916, 889)\n",
      "Match found in frame 945!\n",
      "Processing frame 950\n",
      "\n",
      "0: 384x640 1 logo, 92.3ms\n",
      "Speed: 3.3ms preprocess, 92.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (456, 163) -> (1916, 888)\n",
      "Match found in frame 950!\n",
      "Processing frame 955\n",
      "\n",
      "0: 384x640 (no detections), 93.7ms\n",
      "Speed: 3.2ms preprocess, 93.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 960\n",
      "\n",
      "0: 384x640 (no detections), 97.9ms\n",
      "Speed: 3.3ms preprocess, 97.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 965\n",
      "\n",
      "0: 384x640 (no detections), 81.1ms\n",
      "Speed: 2.6ms preprocess, 81.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 970\n",
      "\n",
      "0: 384x640 (no detections), 77.1ms\n",
      "Speed: 2.4ms preprocess, 77.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 975\n",
      "\n",
      "0: 384x640 (no detections), 89.1ms\n",
      "Speed: 2.9ms preprocess, 89.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 980\n",
      "\n",
      "0: 384x640 (no detections), 82.6ms\n",
      "Speed: 2.8ms preprocess, 82.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 985\n",
      "\n",
      "0: 384x640 (no detections), 81.2ms\n",
      "Speed: 2.8ms preprocess, 81.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 990\n",
      "\n",
      "0: 384x640 (no detections), 74.4ms\n",
      "Speed: 2.7ms preprocess, 74.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 995\n",
      "\n",
      "0: 384x640 (no detections), 80.1ms\n",
      "Speed: 2.4ms preprocess, 80.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1000\n",
      "\n",
      "0: 384x640 (no detections), 80.9ms\n",
      "Speed: 2.7ms preprocess, 80.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1005\n",
      "\n",
      "0: 384x640 (no detections), 88.6ms\n",
      "Speed: 2.8ms preprocess, 88.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1010\n",
      "\n",
      "0: 384x640 (no detections), 89.0ms\n",
      "Speed: 3.2ms preprocess, 89.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1015\n",
      "\n",
      "0: 384x640 (no detections), 85.9ms\n",
      "Speed: 3.0ms preprocess, 85.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1020\n",
      "\n",
      "0: 384x640 (no detections), 84.0ms\n",
      "Speed: 2.7ms preprocess, 84.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1025\n",
      "\n",
      "0: 384x640 (no detections), 86.9ms\n",
      "Speed: 3.1ms preprocess, 86.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1030\n",
      "\n",
      "0: 384x640 (no detections), 88.6ms\n",
      "Speed: 2.7ms preprocess, 88.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1035\n",
      "\n",
      "0: 384x640 (no detections), 82.4ms\n",
      "Speed: 2.9ms preprocess, 82.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1040\n",
      "\n",
      "0: 384x640 (no detections), 81.0ms\n",
      "Speed: 2.7ms preprocess, 81.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1045\n",
      "\n",
      "0: 384x640 (no detections), 104.6ms\n",
      "Speed: 3.0ms preprocess, 104.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1050\n",
      "\n",
      "0: 384x640 (no detections), 97.0ms\n",
      "Speed: 2.9ms preprocess, 97.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1055\n",
      "\n",
      "0: 384x640 (no detections), 86.1ms\n",
      "Speed: 2.8ms preprocess, 86.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1060\n",
      "\n",
      "0: 384x640 (no detections), 81.2ms\n",
      "Speed: 2.7ms preprocess, 81.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1065\n",
      "\n",
      "0: 384x640 (no detections), 87.5ms\n",
      "Speed: 2.9ms preprocess, 87.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1070\n",
      "\n",
      "0: 384x640 (no detections), 84.9ms\n",
      "Speed: 2.8ms preprocess, 84.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1075\n",
      "\n",
      "0: 384x640 (no detections), 84.2ms\n",
      "Speed: 2.9ms preprocess, 84.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1080\n",
      "\n",
      "0: 384x640 (no detections), 90.3ms\n",
      "Speed: 2.8ms preprocess, 90.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1085\n",
      "\n",
      "0: 384x640 (no detections), 83.4ms\n",
      "Speed: 2.4ms preprocess, 83.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1090\n",
      "\n",
      "0: 384x640 (no detections), 85.6ms\n",
      "Speed: 2.7ms preprocess, 85.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1095\n",
      "\n",
      "0: 384x640 (no detections), 81.4ms\n",
      "Speed: 3.4ms preprocess, 81.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1100\n",
      "\n",
      "0: 384x640 (no detections), 81.7ms\n",
      "Speed: 2.6ms preprocess, 81.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1105\n",
      "\n",
      "0: 384x640 (no detections), 85.4ms\n",
      "Speed: 2.8ms preprocess, 85.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1110\n",
      "\n",
      "0: 384x640 (no detections), 87.7ms\n",
      "Speed: 3.5ms preprocess, 87.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1115\n",
      "\n",
      "0: 384x640 (no detections), 89.7ms\n",
      "Speed: 2.9ms preprocess, 89.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1120\n",
      "\n",
      "0: 384x640 (no detections), 80.4ms\n",
      "Speed: 2.7ms preprocess, 80.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1125\n",
      "\n",
      "0: 384x640 (no detections), 84.5ms\n",
      "Speed: 2.9ms preprocess, 84.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1130\n",
      "\n",
      "0: 384x640 (no detections), 81.1ms\n",
      "Speed: 2.6ms preprocess, 81.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1135\n",
      "\n",
      "0: 384x640 (no detections), 92.9ms\n",
      "Speed: 3.0ms preprocess, 92.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1140\n",
      "\n",
      "0: 384x640 (no detections), 100.5ms\n",
      "Speed: 2.8ms preprocess, 100.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1145\n",
      "\n",
      "0: 384x640 (no detections), 98.8ms\n",
      "Speed: 3.4ms preprocess, 98.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1150\n",
      "\n",
      "0: 384x640 1 logo, 101.2ms\n",
      "Speed: 2.9ms preprocess, 101.2ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (303, 180) -> (1536, 1080)\n",
      "Processing frame 1155\n",
      "\n",
      "0: 384x640 1 logo, 105.2ms\n",
      "Speed: 3.6ms preprocess, 105.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (305, 180) -> (1537, 1080)\n",
      "Processing frame 1160\n",
      "\n",
      "0: 384x640 1 logo, 111.2ms\n",
      "Speed: 3.2ms preprocess, 111.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (304, 179) -> (1535, 1080)\n",
      "Processing frame 1165\n",
      "\n",
      "0: 384x640 1 logo, 102.1ms\n",
      "Speed: 3.3ms preprocess, 102.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (307, 178) -> (1537, 1080)\n",
      "Processing frame 1170\n",
      "\n",
      "0: 384x640 1 logo, 100.1ms\n",
      "Speed: 3.3ms preprocess, 100.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (308, 181) -> (1536, 1080)\n",
      "Processing frame 1175\n",
      "\n",
      "0: 384x640 1 logo, 105.1ms\n",
      "Speed: 3.3ms preprocess, 105.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (305, 180) -> (1537, 1080)\n",
      "Processing frame 1180\n",
      "\n",
      "0: 384x640 1 logo, 98.7ms\n",
      "Speed: 3.5ms preprocess, 98.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (305, 181) -> (1536, 1080)\n",
      "Processing frame 1185\n",
      "\n",
      "0: 384x640 1 logo, 101.7ms\n",
      "Speed: 3.5ms preprocess, 101.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (307, 179) -> (1537, 1080)\n",
      "Processing frame 1190\n",
      "\n",
      "0: 384x640 1 logo, 139.0ms\n",
      "Speed: 3.1ms preprocess, 139.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (310, 181) -> (1535, 1080)\n",
      "Processing frame 1195\n",
      "\n",
      "0: 384x640 1 logo, 98.4ms\n",
      "Speed: 3.3ms preprocess, 98.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (308, 180) -> (1537, 1080)\n",
      "Processing frame 1200\n",
      "\n",
      "0: 384x640 1 logo, 94.5ms\n",
      "Speed: 3.5ms preprocess, 94.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (304, 179) -> (1540, 1080)\n",
      "Processing frame 1205\n",
      "\n",
      "0: 384x640 1 logo, 98.9ms\n",
      "Speed: 3.7ms preprocess, 98.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (282, 178) -> (1542, 1080)\n",
      "Processing frame 1210\n",
      "\n",
      "0: 384x640 (no detections), 92.1ms\n",
      "Speed: 3.3ms preprocess, 92.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1215\n",
      "\n",
      "0: 384x640 (no detections), 95.0ms\n",
      "Speed: 2.9ms preprocess, 95.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1220\n",
      "\n",
      "0: 384x640 (no detections), 104.7ms\n",
      "Speed: 3.1ms preprocess, 104.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1225\n",
      "\n",
      "0: 384x640 (no detections), 81.9ms\n",
      "Speed: 3.3ms preprocess, 81.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1230\n",
      "\n",
      "0: 384x640 (no detections), 85.5ms\n",
      "Speed: 2.7ms preprocess, 85.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1235\n",
      "\n",
      "0: 384x640 (no detections), 100.1ms\n",
      "Speed: 3.8ms preprocess, 100.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1240\n",
      "\n",
      "0: 384x640 (no detections), 80.9ms\n",
      "Speed: 2.6ms preprocess, 80.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1245\n",
      "\n",
      "0: 384x640 (no detections), 81.9ms\n",
      "Speed: 2.4ms preprocess, 81.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1250\n",
      "\n",
      "0: 384x640 (no detections), 84.2ms\n",
      "Speed: 2.9ms preprocess, 84.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1255\n",
      "\n",
      "0: 384x640 (no detections), 82.0ms\n",
      "Speed: 2.6ms preprocess, 82.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1260\n",
      "\n",
      "0: 384x640 (no detections), 83.6ms\n",
      "Speed: 3.0ms preprocess, 83.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1265\n",
      "\n",
      "0: 384x640 (no detections), 84.9ms\n",
      "Speed: 3.1ms preprocess, 84.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1270\n",
      "\n",
      "0: 384x640 (no detections), 79.2ms\n",
      "Speed: 2.7ms preprocess, 79.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1275\n",
      "\n",
      "0: 384x640 (no detections), 78.0ms\n",
      "Speed: 2.8ms preprocess, 78.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1280\n",
      "\n",
      "0: 384x640 (no detections), 92.5ms\n",
      "Speed: 2.8ms preprocess, 92.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1285\n",
      "\n",
      "0: 384x640 (no detections), 82.6ms\n",
      "Speed: 2.9ms preprocess, 82.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1290\n",
      "\n",
      "0: 384x640 (no detections), 86.9ms\n",
      "Speed: 2.4ms preprocess, 86.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1295\n",
      "\n",
      "0: 384x640 (no detections), 121.0ms\n",
      "Speed: 4.2ms preprocess, 121.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1300\n",
      "\n",
      "0: 384x640 (no detections), 87.4ms\n",
      "Speed: 2.8ms preprocess, 87.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1305\n",
      "\n",
      "0: 384x640 (no detections), 94.5ms\n",
      "Speed: 3.0ms preprocess, 94.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1310\n",
      "\n",
      "0: 384x640 (no detections), 87.7ms\n",
      "Speed: 2.9ms preprocess, 87.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1315\n",
      "\n",
      "0: 384x640 (no detections), 93.2ms\n",
      "Speed: 3.1ms preprocess, 93.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1320\n",
      "\n",
      "0: 384x640 (no detections), 84.4ms\n",
      "Speed: 2.8ms preprocess, 84.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1325\n",
      "\n",
      "0: 384x640 1 logo, 86.0ms\n",
      "Speed: 3.1ms preprocess, 86.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (232, 0) -> (1903, 991)\n",
      "Processing frame 1330\n",
      "\n",
      "0: 384x640 1 logo, 95.0ms\n",
      "Speed: 3.2ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (247, 9) -> (1907, 975)\n",
      "Processing frame 1335\n",
      "\n",
      "0: 384x640 1 logo, 102.8ms\n",
      "Speed: 3.5ms preprocess, 102.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (268, 12) -> (1905, 976)\n",
      "Processing frame 1340\n",
      "\n",
      "0: 384x640 (no detections), 94.7ms\n",
      "Speed: 3.5ms preprocess, 94.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1345\n",
      "\n",
      "0: 384x640 (no detections), 86.2ms\n",
      "Speed: 3.0ms preprocess, 86.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1350\n",
      "\n",
      "0: 384x640 (no detections), 85.5ms\n",
      "Speed: 2.7ms preprocess, 85.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1355\n",
      "\n",
      "0: 384x640 (no detections), 105.1ms\n",
      "Speed: 2.8ms preprocess, 105.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1360\n",
      "\n",
      "0: 384x640 (no detections), 81.7ms\n",
      "Speed: 2.5ms preprocess, 81.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1365\n",
      "\n",
      "0: 384x640 1 logo, 92.4ms\n",
      "Speed: 3.0ms preprocess, 92.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (71, 0) -> (1917, 982)\n",
      "Processing frame 1370\n",
      "\n",
      "0: 384x640 1 logo, 101.6ms\n",
      "Speed: 3.5ms preprocess, 101.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (57, 0) -> (1917, 971)\n",
      "Processing frame 1375\n",
      "\n",
      "0: 384x640 1 logo, 114.3ms\n",
      "Speed: 3.3ms preprocess, 114.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Logo 0 detected at coordinates: (83, 0) -> (1917, 962)\n",
      "Processing frame 1380\n",
      "\n",
      "0: 384x640 (no detections), 102.5ms\n",
      "Speed: 3.3ms preprocess, 102.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1385\n",
      "\n",
      "0: 384x640 (no detections), 101.7ms\n",
      "Speed: 3.4ms preprocess, 101.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1390\n",
      "\n",
      "0: 384x640 (no detections), 98.2ms\n",
      "Speed: 3.0ms preprocess, 98.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1395\n",
      "\n",
      "0: 384x640 (no detections), 86.0ms\n",
      "Speed: 2.7ms preprocess, 86.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1400\n",
      "\n",
      "0: 384x640 (no detections), 84.0ms\n",
      "Speed: 3.1ms preprocess, 84.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1405\n",
      "\n",
      "0: 384x640 (no detections), 90.9ms\n",
      "Speed: 2.9ms preprocess, 90.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1410\n",
      "\n",
      "0: 384x640 (no detections), 93.2ms\n",
      "Speed: 3.1ms preprocess, 93.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1415\n",
      "\n",
      "0: 384x640 (no detections), 90.0ms\n",
      "Speed: 2.6ms preprocess, 90.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1420\n",
      "\n",
      "0: 384x640 (no detections), 85.1ms\n",
      "Speed: 2.7ms preprocess, 85.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1425\n",
      "\n",
      "0: 384x640 (no detections), 113.3ms\n",
      "Speed: 4.0ms preprocess, 113.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1430\n",
      "\n",
      "0: 384x640 (no detections), 90.8ms\n",
      "Speed: 2.7ms preprocess, 90.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1435\n",
      "\n",
      "0: 384x640 (no detections), 91.5ms\n",
      "Speed: 3.1ms preprocess, 91.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1440\n",
      "\n",
      "0: 384x640 (no detections), 96.2ms\n",
      "Speed: 3.1ms preprocess, 96.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1445\n",
      "\n",
      "0: 384x640 (no detections), 90.0ms\n",
      "Speed: 3.0ms preprocess, 90.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1450\n",
      "\n",
      "0: 384x640 (no detections), 89.3ms\n",
      "Speed: 3.0ms preprocess, 89.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1455\n",
      "\n",
      "0: 384x640 (no detections), 91.7ms\n",
      "Speed: 2.9ms preprocess, 91.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1460\n",
      "\n",
      "0: 384x640 (no detections), 94.4ms\n",
      "Speed: 3.4ms preprocess, 94.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1465\n",
      "\n",
      "0: 384x640 (no detections), 89.2ms\n",
      "Speed: 2.8ms preprocess, 89.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1470\n",
      "\n",
      "0: 384x640 (no detections), 89.6ms\n",
      "Speed: 2.7ms preprocess, 89.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1475\n",
      "\n",
      "0: 384x640 (no detections), 90.8ms\n",
      "Speed: 2.6ms preprocess, 90.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1480\n",
      "\n",
      "0: 384x640 (no detections), 93.6ms\n",
      "Speed: 3.2ms preprocess, 93.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1485\n",
      "\n",
      "0: 384x640 (no detections), 98.2ms\n",
      "Speed: 3.1ms preprocess, 98.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1490\n",
      "\n",
      "0: 384x640 (no detections), 79.8ms\n",
      "Speed: 2.4ms preprocess, 79.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1495\n",
      "\n",
      "0: 384x640 (no detections), 90.0ms\n",
      "Speed: 3.2ms preprocess, 90.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1500\n",
      "\n",
      "0: 384x640 (no detections), 88.3ms\n",
      "Speed: 2.7ms preprocess, 88.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1505\n",
      "\n",
      "0: 384x640 (no detections), 101.9ms\n",
      "Speed: 3.1ms preprocess, 101.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1510\n",
      "\n",
      "0: 384x640 (no detections), 92.2ms\n",
      "Speed: 2.8ms preprocess, 92.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1515\n",
      "\n",
      "0: 384x640 (no detections), 89.7ms\n",
      "Speed: 2.7ms preprocess, 89.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1520\n",
      "\n",
      "0: 384x640 (no detections), 87.3ms\n",
      "Speed: 2.7ms preprocess, 87.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1525\n",
      "\n",
      "0: 384x640 (no detections), 118.2ms\n",
      "Speed: 2.7ms preprocess, 118.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1530\n",
      "\n",
      "0: 384x640 (no detections), 89.9ms\n",
      "Speed: 2.9ms preprocess, 89.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1535\n",
      "\n",
      "0: 384x640 (no detections), 115.0ms\n",
      "Speed: 3.7ms preprocess, 115.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1540\n",
      "\n",
      "0: 384x640 (no detections), 104.8ms\n",
      "Speed: 3.4ms preprocess, 104.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1545\n",
      "\n",
      "0: 384x640 (no detections), 99.3ms\n",
      "Speed: 2.7ms preprocess, 99.3ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1550\n",
      "\n",
      "0: 384x640 (no detections), 110.3ms\n",
      "Speed: 3.0ms preprocess, 110.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1555\n",
      "\n",
      "0: 384x640 (no detections), 97.7ms\n",
      "Speed: 2.7ms preprocess, 97.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1560\n",
      "\n",
      "0: 384x640 (no detections), 89.3ms\n",
      "Speed: 2.8ms preprocess, 89.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1565\n",
      "\n",
      "0: 384x640 (no detections), 84.2ms\n",
      "Speed: 2.8ms preprocess, 84.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1570\n",
      "\n",
      "0: 384x640 (no detections), 99.4ms\n",
      "Speed: 2.8ms preprocess, 99.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1575\n",
      "\n",
      "0: 384x640 (no detections), 116.7ms\n",
      "Speed: 4.2ms preprocess, 116.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1580\n",
      "\n",
      "0: 384x640 (no detections), 96.7ms\n",
      "Speed: 3.3ms preprocess, 96.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1585\n",
      "\n",
      "0: 384x640 (no detections), 95.8ms\n",
      "Speed: 3.1ms preprocess, 95.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1590\n",
      "\n",
      "0: 384x640 (no detections), 90.8ms\n",
      "Speed: 3.8ms preprocess, 90.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1595\n",
      "\n",
      "0: 384x640 (no detections), 98.5ms\n",
      "Speed: 3.1ms preprocess, 98.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1600\n",
      "\n",
      "0: 384x640 (no detections), 92.5ms\n",
      "Speed: 3.0ms preprocess, 92.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1605\n",
      "\n",
      "0: 384x640 (no detections), 92.6ms\n",
      "Speed: 3.1ms preprocess, 92.6ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1610\n",
      "\n",
      "0: 384x640 (no detections), 85.0ms\n",
      "Speed: 3.2ms preprocess, 85.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1615\n",
      "\n",
      "0: 384x640 (no detections), 94.2ms\n",
      "Speed: 3.1ms preprocess, 94.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1620\n",
      "\n",
      "0: 384x640 (no detections), 86.7ms\n",
      "Speed: 3.2ms preprocess, 86.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1625\n",
      "\n",
      "0: 384x640 (no detections), 134.8ms\n",
      "Speed: 4.2ms preprocess, 134.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1630\n",
      "\n",
      "0: 384x640 (no detections), 99.5ms\n",
      "Speed: 2.9ms preprocess, 99.5ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1635\n",
      "\n",
      "0: 384x640 (no detections), 89.9ms\n",
      "Speed: 2.9ms preprocess, 89.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1640\n",
      "\n",
      "0: 384x640 (no detections), 104.9ms\n",
      "Speed: 3.5ms preprocess, 104.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1645\n",
      "\n",
      "0: 384x640 (no detections), 97.8ms\n",
      "Speed: 2.9ms preprocess, 97.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1650\n",
      "\n",
      "0: 384x640 (no detections), 97.1ms\n",
      "Speed: 2.8ms preprocess, 97.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1655\n",
      "\n",
      "0: 384x640 (no detections), 95.6ms\n",
      "Speed: 2.9ms preprocess, 95.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1660\n",
      "\n",
      "0: 384x640 (no detections), 104.2ms\n",
      "Speed: 3.4ms preprocess, 104.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1665\n",
      "\n",
      "0: 384x640 (no detections), 99.4ms\n",
      "Speed: 3.0ms preprocess, 99.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1670\n",
      "\n",
      "0: 384x640 (no detections), 98.0ms\n",
      "Speed: 3.0ms preprocess, 98.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1675\n",
      "\n",
      "0: 384x640 (no detections), 123.6ms\n",
      "Speed: 4.3ms preprocess, 123.6ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1680\n",
      "\n",
      "0: 384x640 (no detections), 85.0ms\n",
      "Speed: 2.9ms preprocess, 85.0ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1685\n",
      "\n",
      "0: 384x640 (no detections), 87.2ms\n",
      "Speed: 2.9ms preprocess, 87.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1690\n",
      "\n",
      "0: 384x640 (no detections), 91.2ms\n",
      "Speed: 3.1ms preprocess, 91.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1695\n",
      "\n",
      "0: 384x640 (no detections), 90.1ms\n",
      "Speed: 2.7ms preprocess, 90.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1700\n",
      "\n",
      "0: 384x640 (no detections), 97.2ms\n",
      "Speed: 3.0ms preprocess, 97.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1705\n",
      "\n",
      "0: 384x640 (no detections), 98.7ms\n",
      "Speed: 2.8ms preprocess, 98.7ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1710\n",
      "\n",
      "0: 384x640 (no detections), 93.4ms\n",
      "Speed: 3.3ms preprocess, 93.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1715\n",
      "\n",
      "0: 384x640 (no detections), 92.1ms\n",
      "Speed: 3.1ms preprocess, 92.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1720\n",
      "\n",
      "0: 384x640 (no detections), 114.7ms\n",
      "Speed: 5.2ms preprocess, 114.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1725\n",
      "\n",
      "0: 384x640 (no detections), 88.8ms\n",
      "Speed: 3.3ms preprocess, 88.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1730\n",
      "\n",
      "0: 384x640 (no detections), 89.7ms\n",
      "Speed: 2.9ms preprocess, 89.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1735\n",
      "\n",
      "0: 384x640 (no detections), 96.6ms\n",
      "Speed: 3.1ms preprocess, 96.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1740\n",
      "\n",
      "0: 384x640 (no detections), 89.1ms\n",
      "Speed: 2.8ms preprocess, 89.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1745\n",
      "\n",
      "0: 384x640 (no detections), 86.6ms\n",
      "Speed: 2.9ms preprocess, 86.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1750\n",
      "\n",
      "0: 384x640 (no detections), 87.1ms\n",
      "Speed: 3.2ms preprocess, 87.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1755\n",
      "\n",
      "0: 384x640 (no detections), 97.1ms\n",
      "Speed: 3.0ms preprocess, 97.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1760\n",
      "\n",
      "0: 384x640 (no detections), 92.9ms\n",
      "Speed: 3.1ms preprocess, 92.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1765\n",
      "\n",
      "0: 384x640 (no detections), 121.2ms\n",
      "Speed: 5.8ms preprocess, 121.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1770\n",
      "\n",
      "0: 384x640 (no detections), 108.8ms\n",
      "Speed: 3.2ms preprocess, 108.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1775\n",
      "\n",
      "0: 384x640 (no detections), 102.0ms\n",
      "Speed: 3.1ms preprocess, 102.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1780\n",
      "\n",
      "0: 384x640 (no detections), 99.5ms\n",
      "Speed: 3.1ms preprocess, 99.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1785\n",
      "\n",
      "0: 384x640 (no detections), 96.8ms\n",
      "Speed: 3.1ms preprocess, 96.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1790\n",
      "\n",
      "0: 384x640 (no detections), 98.3ms\n",
      "Speed: 3.3ms preprocess, 98.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1795\n",
      "\n",
      "0: 384x640 (no detections), 91.1ms\n",
      "Speed: 2.9ms preprocess, 91.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1800\n",
      "\n",
      "0: 384x640 (no detections), 106.5ms\n",
      "Speed: 3.0ms preprocess, 106.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1805\n",
      "\n",
      "0: 384x640 (no detections), 103.5ms\n",
      "Speed: 3.1ms preprocess, 103.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1810\n",
      "\n",
      "0: 384x640 (no detections), 125.3ms\n",
      "Speed: 6.7ms preprocess, 125.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1815\n",
      "\n",
      "0: 384x640 (no detections), 99.7ms\n",
      "Speed: 3.1ms preprocess, 99.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processing frame 1820\n",
      "\n",
      "0: 384x640 (no detections), 93.0ms\n",
      "Speed: 3.1ms preprocess, 93.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "No logos detected in one or both images.\n",
      "Processed video saved as output_video.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_video_path = \"starbucks_video.mp4\"  # path to input video\n",
    "output_video_path = \"output_video.mp4\"  # output processed video\n",
    "reference_image_path = \"starbucks4.png\"  # reference image for logo detection\n",
    "\n",
    "process_video(input_video_path, output_video_path, reference_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOOnCnaC8uoqc7glmvGYv3p",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "03c272b80fdf46ea9a85424e44d5e8d0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_411bf6bef47241f59d96bfedc5801663",
      "max": 862328,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_57fd0dbb654c45e8b2f908588c1f71d5",
      "value": 862328
     }
    },
    "03f888d62d6541789da05722e5834dd5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "093615d7c6874980b0715a55ad37166b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4c618e720af425c84bcce18265b1a2d",
      "placeholder": "​",
      "style": "IPY_MODEL_270397b6f4e7416ba98224421a592ae0",
      "value": " 316/316 [00:00&lt;00:00, 11.0kB/s]"
     }
    },
    "0f5aeaecb12440a1a5e0cdb359d77e30": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_2d81f48b0c484d7785a7ef915f1d5a0b",
       "IPY_MODEL_f70e63604ba944fbb0ed0ffaf8506f9a",
       "IPY_MODEL_fdbf41b5cbec48a4916b77d5ebb70ac2"
      ],
      "layout": "IPY_MODEL_bdb958129cc74a73b326c9c5d0de9283"
     }
    },
    "107575eef36045d9a2054301e4dbcad8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12be1112e1494b088c714c35aca50486": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d972f458ec4b48dfae5dc7663aed76c0",
       "IPY_MODEL_4c22269fefb24294821461eecc66b619",
       "IPY_MODEL_d07d45babfa141338ce0d0f65707a331"
      ],
      "layout": "IPY_MODEL_3991384dfaa84c578e7f3c1bffab85de"
     }
    },
    "159187c818b54972941ab58a09c9bbb3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_be58cc0cfe0c417f83f86fd254542c7a",
       "IPY_MODEL_363ed3e58f304861a9e3fcdfd652c73e",
       "IPY_MODEL_36adee2c781e476b8c35ec9ec53c66f4"
      ],
      "layout": "IPY_MODEL_107575eef36045d9a2054301e4dbcad8"
     }
    },
    "188a2637964c4f06b6d9d7aa570df3f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "19b39c7b58114c71a2669b6ec10ae008": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ad5e854641c454a820c56d30892c105": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_efaa27f863184e18af5a0f31cc90329f",
       "IPY_MODEL_6468af196d7d48918e6dcdc65dc91c92",
       "IPY_MODEL_3097fb8a15e64cf68912190dd31d1096"
      ],
      "layout": "IPY_MODEL_44c2163472d14ea9abbde6961a20dd38"
     }
    },
    "1b94f8aa6ae7406ba91df3f35f7da41f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "1c6235a672c3443e848ed440a3182155": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42840d6628474e9d8c44f1fdef7b3d46",
      "placeholder": "​",
      "style": "IPY_MODEL_b71cb728be3c46e3b3b5e5f2ff2d57b4",
      "value": " 276/276 [00:00&lt;00:00, 21.4kB/s]"
     }
    },
    "1c73996b02604302b3e0f67c41e7b11f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1ca277659fe949d093a96e95dacde41e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1f14f84fd26a46caabb467f61d10da63": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "215be1c676dd42998a6ffbf69fe1c9d4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2206eb6700404d688d2bc5713239a5e1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4b8d433bb404a9fa8c024d17d518d13",
      "max": 316,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c5b5370b75a240f2a87f5a732c7a43fa",
      "value": 316
     }
    },
    "2337bfaa230f42869ec3488ee4e9375d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "23e662abd1dd460cb0fad3acd58da2a5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2454641381d144c2aca2dcfdf2a99c05": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "258bdbe65a604233ae5d5bbbdd0d2961": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "270397b6f4e7416ba98224421a592ae0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "29d3a89e685247a8ba306a895558420e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2d81f48b0c484d7785a7ef915f1d5a0b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1ca277659fe949d093a96e95dacde41e",
      "placeholder": "​",
      "style": "IPY_MODEL_23e662abd1dd460cb0fad3acd58da2a5",
      "value": "tokenizer.json: 100%"
     }
    },
    "2f9c26f5a3374b99834e81c4f1ff7688": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "30096ffabac24d048738981bdc19efbf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46e3d38d5a304e938cfd19700e619e13",
      "max": 4186,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fca583db47754069bbee6323ee9f5391",
      "value": 4186
     }
    },
    "3097fb8a15e64cf68912190dd31d1096": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_89f7f053443b476c97c2bca76010a003",
      "placeholder": "​",
      "style": "IPY_MODEL_4f18e3cc63e5439fa4a68141abf2cb05",
      "value": " 592/592 [00:00&lt;00:00, 31.1kB/s]"
     }
    },
    "3570f8e3d279499dae74c64aa94a728c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "363ed3e58f304861a9e3fcdfd652c73e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e4fa653c579a48b6a75a06b1d262694e",
      "max": 524657,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_67bef8f6e3c0417e8a84d0eeb19a128c",
      "value": 524657
     }
    },
    "36adee2c781e476b8c35ec9ec53c66f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_efc544d15b4f4d73b2e77684b283feab",
      "placeholder": "​",
      "style": "IPY_MODEL_98c1d149972b4b33b2878daae8036eaf",
      "value": " 525k/525k [00:00&lt;00:00, 12.0MB/s]"
     }
    },
    "37981d55d5d84b25a6c0c07bf259ccd3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "37d3414e58ec4ef7907a4ff5d31f9d3c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3991384dfaa84c578e7f3c1bffab85de": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3c5e9bd832a14559996eb1f276fafe77": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3e1cd294107c4a62bd0bf3d02f3242f5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_56447ac94d7c4a67bdc1e8419cfd4911",
       "IPY_MODEL_aa2870ea7c8e41eca4ee02d90592a109",
       "IPY_MODEL_e135dd10cd6a41dda81831cfe998d5bc"
      ],
      "layout": "IPY_MODEL_03f888d62d6541789da05722e5834dd5"
     }
    },
    "3e1f2d0cf8ba4baf8d22be0bbafd2742": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "411bf6bef47241f59d96bfedc5801663": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "41355badb84143138a9e25d31159ce43": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d24305fd08f4417881203bb8950b8ecb",
      "placeholder": "​",
      "style": "IPY_MODEL_958dfb8fc18547d39e5a0d6553312767",
      "value": " 605M/605M [00:02&lt;00:00, 236MB/s]"
     }
    },
    "423391843f19413a8c55857052df9647": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_215be1c676dd42998a6ffbf69fe1c9d4",
      "placeholder": "​",
      "style": "IPY_MODEL_7444d9f63cb74a83867d8e4f2cf3b078",
      "value": " 4.19k/4.19k [00:00&lt;00:00, 223kB/s]"
     }
    },
    "42840d6628474e9d8c44f1fdef7b3d46": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44c2163472d14ea9abbde6961a20dd38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4565c74c30364ee5b9e2b1b6314a2017": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_37d3414e58ec4ef7907a4ff5d31f9d3c",
      "placeholder": "​",
      "style": "IPY_MODEL_9249a8908dba44b8a399b667ecd59f03",
      "value": " 69.9k/69.9k [00:00&lt;00:00, 1.43MB/s]"
     }
    },
    "4591fbc1c0474988ad5cf9f58302b3bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4675a2c80a31444fa4e54a3c55979268": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "46e3d38d5a304e938cfd19700e619e13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4adc2ac7fb8741289cf3a08f0208cbc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ad7b04f04f4a4cdd8a2b58f9ebd076b7",
       "IPY_MODEL_8693b9e4971742079720c4d035b2480b",
       "IPY_MODEL_8f4060e053294bf182a010b9d1c3bb96"
      ],
      "layout": "IPY_MODEL_63f6371bd1564d2d9c85c07d472b4dbf"
     }
    },
    "4b9c0594290c466485a8bb55c721030d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4c22269fefb24294821461eecc66b619": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f8854b8390124e7fa628cd6c65bbc1b1",
      "max": 349877750,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_83a36c03249b4a5c811c24a89d8378d4",
      "value": 349877750
     }
    },
    "4f18e3cc63e5439fa4a68141abf2cb05": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f96af94c3f54f7e93f1f4396943eef7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "510d8ff6088f4033ac28719205b3f750": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5267ee60df3c4899bb4446c9684a789b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "56447ac94d7c4a67bdc1e8419cfd4911": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_fddb427005eb45a3a238dab7fdc7e70e",
      "placeholder": "​",
      "style": "IPY_MODEL_e80c99c4467545738f204938112d3aa9",
      "value": "special_tokens_map.json: 100%"
     }
    },
    "57828f91158a4683b156d48a40986dc6": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "57fd0dbb654c45e8b2f908588c1f71d5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "5cd68ac1551440758f9aa879a60ea3db": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5fd18561fca841eabaaff88287f73aaa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "62f9b10a279c48ac8e0fe05dd5a8a3f1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "63f6371bd1564d2d9c85c07d472b4dbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6468af196d7d48918e6dcdc65dc91c92": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_258bdbe65a604233ae5d5bbbdd0d2961",
      "max": 592,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_cce62f92d53c4cbc8ddbb7b8490e5642",
      "value": 592
     }
    },
    "65e392c6684f44179f485c7d717c06b8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "667abc5b5d6441668b0f2dffafdd6638": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "67bef8f6e3c0417e8a84d0eeb19a128c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "6e6aa27b5fe243cd97955a5929487ce4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ea91d7399fa448bba139fadd28132074",
      "placeholder": "​",
      "style": "IPY_MODEL_29d3a89e685247a8ba306a895558420e",
      "value": "vocab.json: 100%"
     }
    },
    "700006591d404f3398d767d41130acf4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7444d9f63cb74a83867d8e4f2cf3b078": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "74a7fdbdd4af4716a0a7bd4a5bfb2a00": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "75ba66eab29243c0823c48088df288c4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "83a36c03249b4a5c811c24a89d8378d4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "83eac6c4021d47e4ae5bc0c66d280d9f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "845dad720be14929b391fd5c72069f73": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "8646c9bfa811413f946a2bc50a1c67af": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_948378b3fb784b88b15d88ac727999fa",
       "IPY_MODEL_8fd6f5ecbc164f5990c30d2102c89e51",
       "IPY_MODEL_41355badb84143138a9e25d31159ce43"
      ],
      "layout": "IPY_MODEL_f4cd7965f3d64ad08cee796b394a2476"
     }
    },
    "8693b9e4971742079720c4d035b2480b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4b9c0594290c466485a8bb55c721030d",
      "max": 605157884,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_845dad720be14929b391fd5c72069f73",
      "value": 605157884
     }
    },
    "89d485d4ddfe4ad3bbee52937b495ccb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89f7f053443b476c97c2bca76010a003": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8b2d72b478a64964854fb3773515b42c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_65e392c6684f44179f485c7d717c06b8",
      "max": 69889,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_4675a2c80a31444fa4e54a3c55979268",
      "value": 69889
     }
    },
    "8f4060e053294bf182a010b9d1c3bb96": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2454641381d144c2aca2dcfdf2a99c05",
      "placeholder": "​",
      "style": "IPY_MODEL_cfbe12e3ffb0456eb748c537699cca4a",
      "value": " 605M/605M [00:05&lt;00:00, 96.7MB/s]"
     }
    },
    "8fd6f5ecbc164f5990c30d2102c89e51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_57828f91158a4683b156d48a40986dc6",
      "max": 605247071,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1f14f84fd26a46caabb467f61d10da63",
      "value": 605247071
     }
    },
    "916be42a53124b62b1a62426c3e26527": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "9249a8908dba44b8a399b667ecd59f03": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "948378b3fb784b88b15d88ac727999fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5fd18561fca841eabaaff88287f73aaa",
      "placeholder": "​",
      "style": "IPY_MODEL_d9cccb9d6f8e49fa95addf0a9e5238ef",
      "value": "pytorch_model.bin: 100%"
     }
    },
    "94da05c849494bb9ba4b819ff3c574dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f96af94c3f54f7e93f1f4396943eef7",
      "placeholder": "​",
      "style": "IPY_MODEL_3570f8e3d279499dae74c64aa94a728c",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "958dfb8fc18547d39e5a0d6553312767": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98c1d149972b4b33b2878daae8036eaf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "98e3fcc7d5a7481fbb9362b2c1247341": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3c5e9bd832a14559996eb1f276fafe77",
      "placeholder": "​",
      "style": "IPY_MODEL_62f9b10a279c48ac8e0fe05dd5a8a3f1",
      "value": "preprocessor_config.json: 100%"
     }
    },
    "99d9a455a4744d35ad798dd1eb4ea95b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f69e1c4fd7954d4caf04acd464bd4758",
       "IPY_MODEL_8b2d72b478a64964854fb3773515b42c",
       "IPY_MODEL_4565c74c30364ee5b9e2b1b6314a2017"
      ],
      "layout": "IPY_MODEL_89d485d4ddfe4ad3bbee52937b495ccb"
     }
    },
    "9a13baa7aa4a49e4ae7f82e0e84d75f7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a6de4ac749f414abee9f342731aef8f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_94da05c849494bb9ba4b819ff3c574dd",
       "IPY_MODEL_f50e450471a9452088dd28e962ae847f",
       "IPY_MODEL_1c6235a672c3443e848ed440a3182155"
      ],
      "layout": "IPY_MODEL_1c73996b02604302b3e0f67c41e7b11f"
     }
    },
    "a4b8d433bb404a9fa8c024d17d518d13": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa2870ea7c8e41eca4ee02d90592a109": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_83eac6c4021d47e4ae5bc0c66d280d9f",
      "max": 389,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e8057d60629c4c25ace6c27c6b7d1457",
      "value": 389
     }
    },
    "ad7b04f04f4a4cdd8a2b58f9ebd076b7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_510d8ff6088f4033ac28719205b3f750",
      "placeholder": "​",
      "style": "IPY_MODEL_3e1f2d0cf8ba4baf8d22be0bbafd2742",
      "value": "model.safetensors: 100%"
     }
    },
    "b5646402495d418a8782dd8247bccdfd": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b71cb728be3c46e3b3b5e5f2ff2d57b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b9377607876e413da8d1dae56a9c019b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b9e6a8e64dff439b969955eb52a1c104": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_98e3fcc7d5a7481fbb9362b2c1247341",
       "IPY_MODEL_2206eb6700404d688d2bc5713239a5e1",
       "IPY_MODEL_093615d7c6874980b0715a55ad37166b"
      ],
      "layout": "IPY_MODEL_74a7fdbdd4af4716a0a7bd4a5bfb2a00"
     }
    },
    "bdb958129cc74a73b326c9c5d0de9283": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be58cc0cfe0c417f83f86fd254542c7a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_edff5823668843fc93b3194d7d200537",
      "placeholder": "​",
      "style": "IPY_MODEL_d4fc1c33cbd14107ae62aa7594288211",
      "value": "merges.txt: 100%"
     }
    },
    "c2333ff3a641453795ade83ca18d1391": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c5b5370b75a240f2a87f5a732c7a43fa": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c8eeaa39dbf04a5b82e8f7709d145377": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cce62f92d53c4cbc8ddbb7b8490e5642": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "cfbe12e3ffb0456eb748c537699cca4a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d07d45babfa141338ce0d0f65707a331": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f9c26f5a3374b99834e81c4f1ff7688",
      "placeholder": "​",
      "style": "IPY_MODEL_667abc5b5d6441668b0f2dffafdd6638",
      "value": " 350M/350M [00:05&lt;00:00, 31.7MB/s]"
     }
    },
    "d24305fd08f4417881203bb8950b8ecb": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d4fc1c33cbd14107ae62aa7594288211": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d972f458ec4b48dfae5dc7663aed76c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c2333ff3a641453795ade83ca18d1391",
      "placeholder": "​",
      "style": "IPY_MODEL_37981d55d5d84b25a6c0c07bf259ccd3",
      "value": "model.safetensors: 100%"
     }
    },
    "d9cccb9d6f8e49fa95addf0a9e5238ef": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "da313ccb05814ab0ae6765db736cd16a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b9377607876e413da8d1dae56a9c019b",
      "placeholder": "​",
      "style": "IPY_MODEL_5267ee60df3c4899bb4446c9684a789b",
      "value": "config.json: 100%"
     }
    },
    "e135dd10cd6a41dda81831cfe998d5bc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b5646402495d418a8782dd8247bccdfd",
      "placeholder": "​",
      "style": "IPY_MODEL_75ba66eab29243c0823c48088df288c4",
      "value": " 389/389 [00:00&lt;00:00, 10.9kB/s]"
     }
    },
    "e21f24abd58a43fc9359d19a3a819154": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e4c618e720af425c84bcce18265b1a2d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e4fa653c579a48b6a75a06b1d262694e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e8057d60629c4c25ace6c27c6b7d1457": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e80c99c4467545738f204938112d3aa9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e97917111f5b4f4ab223a597666de83d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ea91d7399fa448bba139fadd28132074": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edff5823668843fc93b3194d7d200537": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "efaa27f863184e18af5a0f31cc90329f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_700006591d404f3398d767d41130acf4",
      "placeholder": "​",
      "style": "IPY_MODEL_e21f24abd58a43fc9359d19a3a819154",
      "value": "tokenizer_config.json: 100%"
     }
    },
    "efc544d15b4f4d73b2e77684b283feab": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f1d12d1f5e7f4129ba55bfc72750e970": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_da313ccb05814ab0ae6765db736cd16a",
       "IPY_MODEL_30096ffabac24d048738981bdc19efbf",
       "IPY_MODEL_423391843f19413a8c55857052df9647"
      ],
      "layout": "IPY_MODEL_f30835cf463e40ff8185d2eab404ed1f"
     }
    },
    "f30835cf463e40ff8185d2eab404ed1f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f4cd7965f3d64ad08cee796b394a2476": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f50e450471a9452088dd28e962ae847f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_19b39c7b58114c71a2669b6ec10ae008",
      "max": 276,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1b94f8aa6ae7406ba91df3f35f7da41f",
      "value": 276
     }
    },
    "f69e1c4fd7954d4caf04acd464bd4758": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ff48f8c198fc4563a98804f4b6b3a55b",
      "placeholder": "​",
      "style": "IPY_MODEL_e97917111f5b4f4ab223a597666de83d",
      "value": "config.json: 100%"
     }
    },
    "f70e63604ba944fbb0ed0ffaf8506f9a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2337bfaa230f42869ec3488ee4e9375d",
      "max": 2224041,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_916be42a53124b62b1a62426c3e26527",
      "value": 2224041
     }
    },
    "f8854b8390124e7fa628cd6c65bbc1b1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb17989c433e4b8b935454ac10fbcdd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c8eeaa39dbf04a5b82e8f7709d145377",
      "placeholder": "​",
      "style": "IPY_MODEL_188a2637964c4f06b6d9d7aa570df3f7",
      "value": " 862k/862k [00:00&lt;00:00, 869kB/s]"
     }
    },
    "fc4aef0638ae448697ad745c07e04fe6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6e6aa27b5fe243cd97955a5929487ce4",
       "IPY_MODEL_03c272b80fdf46ea9a85424e44d5e8d0",
       "IPY_MODEL_fb17989c433e4b8b935454ac10fbcdd8"
      ],
      "layout": "IPY_MODEL_9a13baa7aa4a49e4ae7f82e0e84d75f7"
     }
    },
    "fca583db47754069bbee6323ee9f5391": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fdbf41b5cbec48a4916b77d5ebb70ac2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5cd68ac1551440758f9aa879a60ea3db",
      "placeholder": "​",
      "style": "IPY_MODEL_4591fbc1c0474988ad5cf9f58302b3bb",
      "value": " 2.22M/2.22M [00:00&lt;00:00, 33.0MB/s]"
     }
    },
    "fddb427005eb45a3a238dab7fdc7e70e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ff48f8c198fc4563a98804f4b6b3a55b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
